{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Domains\n",
    "\n",
    "This library is designed to be extensible to new domains. To evaluate a model on a custom domain, you need to:\n",
    "\n",
    "1. Define your dataset\n",
    "2. Implement an evaluator\n",
    "3. Implement a model adaptor\n",
    "\n",
    "The following example demonstrates these steps on the pattern matching domain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define your dataset\n",
    "\n",
    "A dataset is an iterator over dataset instances satisfying a schema. The schema is defined by a class that inherits from `Instance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genlm.eval import Instance\n",
    "\n",
    "\n",
    "class PatternMatchingInstance(Instance):\n",
    "    \"\"\"Schema for a pattern matching instance.\"\"\"\n",
    "\n",
    "    pattern: str\n",
    "    instance_id: int\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"pattern: {self.pattern} (id: {self.instance_id})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset schema, you can define a dataset by subclassing `Dataset` and implementing an `__iter__` method which yields instances of the schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genlm.eval import Dataset\n",
    "\n",
    "\n",
    "class PatternMatchingDataset(Dataset[PatternMatchingInstance]):\n",
    "    \"\"\"Dataset for pattern matching evaluation.\"\"\"\n",
    "\n",
    "    def __init__(self, patterns):\n",
    "        self.patterns = patterns\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate over regex patterns.\n",
    "\n",
    "        Returns:\n",
    "            (Iterator[PatternMatchingInstance]): Iterator over regex instances.\n",
    "        \"\"\"\n",
    "        for pattern_id, pattern in enumerate(self.patterns):\n",
    "            yield PatternMatchingInstance(pattern=pattern, instance_id=pattern_id)\n",
    "\n",
    "    @property\n",
    "    def schema(self):\n",
    "        \"\"\"Get the schema class for this dataset.\"\"\"\n",
    "        return PatternMatchingInstance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Implement an evaluator\n",
    "\n",
    "An evaluator is the class responsible for scoring model outputs. Subclasses must minimally implement the `evaluate_sample` method which takes an instance and a response and returns an evaluation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "from genlm.eval import Evaluator, EvaluationResult\n",
    "\n",
    "\n",
    "class PatternMatchingEvaluator(Evaluator[PatternMatchingInstance]):\n",
    "    \"\"\"Evaluator for pattern matching.\"\"\"\n",
    "\n",
    "    def evaluate_sample(self, instance, response):\n",
    "        \"\"\"Evaluate if a response matches the regex pattern.\"\"\"\n",
    "        is_valid = regex.compile(instance.pattern).fullmatch(response) is not None\n",
    "        return EvaluationResult(\n",
    "            score=int(is_valid), desc=\"valid\" if is_valid else \"invalid\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement a model adaptor\n",
    "\n",
    "A model adaptor is an async callable that takes a `PatternMatchingInstance` and returns a `ModelOutput`. For this example, we'll use a constrained `genlm.control.PromptedLLM` to generate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/genlm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/genlm/lib/python3.11/site-packages/genlm/backend/tokenization/vocab.py:98: UserWarning: Duplicate tokens found in string vocabulary. This may lead to downstream issues with the string vocabulary; we recommend using the byte vocabulary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from genlm.control import PromptedLLM, AWRS\n",
    "from genlm.eval import ModelOutput, ModelResponse\n",
    "from genlm.eval.domains.pattern_matching import (\n",
    "    default_prompt_formatter,\n",
    "    PatternPotential,\n",
    ")\n",
    "\n",
    "# Load an LLM\n",
    "LLM = PromptedLLM.from_name(\"gpt2\", eos_tokens=[b\"\\n\", b\"\\n\\n\"])\n",
    "\n",
    "\n",
    "async def model(instance, output_dir, replicate):\n",
    "    # Set the prompt for the LLM.\n",
    "    LLM.prompt_ids = default_prompt_formatter(\n",
    "        LLM.model.tokenizer, instance, use_chat_format=False\n",
    "    )\n",
    "\n",
    "    # Define a potential that ensures the generated text matches the pattern\n",
    "    potential = PatternPotential(instance.pattern).coerce(LLM, f=b\"\".join)\n",
    "\n",
    "    # Define an adaptive weighted rejection sampler to sample tokens from the constrained model.\n",
    "    sampler = AWRS(LLM, potential)\n",
    "\n",
    "    # Run SMC to sample sequences from the constrained model.\n",
    "    sequences = await sampler.smc(\n",
    "        n_particles=5,\n",
    "        ess_threshold=0.5,\n",
    "        max_tokens=100,\n",
    "    )\n",
    "\n",
    "    # Return the sampled sequences and their probabilities as a ModelOutput.\n",
    "    return ModelOutput(\n",
    "        responses=[\n",
    "            ModelResponse(response=sequence, weight=prob)\n",
    "            for sequence, prob in sequences.decoded_posterior.items()\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the evaluation\n",
    "\n",
    "Using the dataset, evaluator, and model adaptor, we can now run the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance instance_id=0 pattern='xy|xz'\n",
      "Mean weighted accuracy (instance): 0.9999999999999999\n",
      "Mean weighted accuracy (total): 0.9999999999999999\n",
      "\n",
      "Instance instance_id=1 pattern='ab|c(e|f)'\n",
      "Mean weighted accuracy (instance): 1.0\n",
      "Mean weighted accuracy (total): 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from genlm.eval import run_evaluation\n",
    "\n",
    "dataset = PatternMatchingDataset([r\"xy|xz\", r\"ab|c(e|f)\"])\n",
    "evaluator = PatternMatchingEvaluator()\n",
    "\n",
    "results = await run_evaluation(\n",
    "    dataset=dataset,\n",
    "    evaluator=evaluator,\n",
    "    model=model,\n",
    "    n_replicates=1,\n",
    "    verbosity=1,\n",
    "    # output_dir=\"results\", # uncomment to save results\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
